{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## My bicycle reinvention in module import issue  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from lib import *\n",
    "\n",
    "Pipeline = pipeline.Pipeline\n",
    "RegressionValidator = pipeline.RegressionValidator\n",
    "\n",
    "DatasetProvider = provider.DatasetProvider\n",
    "DatasetUploader = provider.DatasetUploader\n",
    "ExpandedWindowIterator = subset_extraction.ExpandedWindowIterator\n",
    "EntityIterator = subset_extraction.EntityIterator\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning, DataConversionWarning\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from statsmodels.tsa.stattools import acf \n",
    "\n",
    "tr = transformers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "CONFIG = {\n",
    "    'validation_window': {\n",
    "        'min_window': 13,\n",
    "        'max_window': 32,\n",
    "    },\n",
    "    'training_window': {\n",
    "        'min': 16\n",
    "    },\n",
    "    'FETCH_DATA': True,\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df_provider = DatasetProvider()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "dataset_paths = [\n",
    "    '/home/denissimo/Repo/fs_project/datasets/sample_submission.csv',\n",
    "    '/home/denissimo/Repo/fs_project/datasets/test.csv',\n",
    "    '/home/denissimo/Repo/fs_project/datasets/shops.csv',\n",
    "    '/home/denissimo/Repo/fs_project/datasets/item_categories.csv',\n",
    "    '/home/denissimo/Repo/fs_project/datasets/sales_train.csv',\n",
    "    '/home/denissimo/Repo/fs_project/datasets/items.csv'\n",
    "]\n",
    "fetched = [\n",
    "    \n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import pickle\n",
    "\n",
    "def load_pickle(dataset, name):\n",
    "    dataset.to_pickle(name + '.pkl')\n",
    "\n",
    "def from_pickle(path):\n",
    "    with open(path, 'rb') as reader:\n",
    "        return pickle.load(reader)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df_provider.file_list = dataset_paths\n",
    "\n",
    "datasets = df_provider.get_dataset()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "sales = datasets['sales_train.csv']\n",
    "items = datasets['items.csv']\n",
    "categories = datasets['item_categories.csv']\n",
    "shops = datasets['shops.csv']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "force_category = {\n",
    "    'category': {\n",
    "        \"PC - Гарнитуры/Наушники\": \"Аксессуары\",\n",
    "        \"Игры MAC - Цифра\": \"Игры\",\n",
    "        \"Игры Android - Цифра\": \"Игры\",\n",
    "        \"Чистые носители (шпиль)\": \"Чистые носители\",\n",
    "        \"Чистые носители (штучные)\": \"Чистые носители\",\n",
    "    },\n",
    "    'shop': {\n",
    "        'Интернет-магазин ЧС': 'Интернет-магазин',\n",
    "        'Цифровой склад 1С-Онлайн': 'Склад',\n",
    "        'Выездная Торговля': 'Выездная Торговля',\n",
    "        '!Якутск Орджоникидзе, 56 фран': 'Якутск',\n",
    "        '!Якутск ТЦ \"Центральный\" фран': 'Якутск',\n",
    "    },\n",
    "}\n",
    "\n",
    "pattern = {\n",
    "    'category': ' - ',\n",
    "    'shop': ' ',\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "sales.date = sales.date.astype('datetime64[ns]')\n",
    "\n",
    "print(\"Before:\", sales.shape)\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "sales = sales.loc[sales.date < np.datetime64(date(2015, 11, 1))]\n",
    "\n",
    "sales_train = sales[\n",
    "    (sales[\"item_cnt_day\"] < 1000)\n",
    "    & (sales[\"item_price\"] > 0)\n",
    "    & (sales[\"item_price\"] < 60000)\n",
    "].copy()\n",
    "print(\"After:\", sales_train.shape)\n",
    "\n",
    "sales.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before: (2935849, 6)\n",
      "After: (2896778, 6)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  date_block_num  shop_id  item_id  item_price  item_cnt_day\n",
       "0 2013-02-01               0       59    22154      999.00           1.0\n",
       "1 2013-03-01               0       25     2552      899.00           1.0\n",
       "2 2013-05-01               0       25     2552      899.00          -1.0\n",
       "3 2013-06-01               0       25     2554     1709.05           1.0\n",
       "4 2013-01-15               0       25     2555     1099.00           1.0"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "make_cat_name = tr.create_name_transformer(force_category['category'], pattern['category'])\n",
    "make_city_name = tr.create_name_transformer(force_category['shop'], pattern['shop'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "data_preprocessing = {}\n",
    "\n",
    "# Add corresponding category and shop id's to each sale\n",
    "data_preprocessing['id_merging_stage'] = lambda dataset: dataset.merge(\n",
    "    items, \n",
    "    on='item_id'\n",
    ").merge(\n",
    "    shops,\n",
    "    on='shop_id'\n",
    ").merge(\n",
    "    categories,\n",
    "    on='item_category_id'\n",
    ")\n",
    "\n",
    "# Add summary among shop_id and category_id above similar time periods (daily intervals)\n",
    "data_preprocessing['summarizing_and_name_merging_stage'] = lambda dataset: dataset.groupby(\n",
    "    ['date', 'date_block_num', 'shop_id', 'item_category_id', 'item_category_name', 'shop_name']\n",
    ").item_cnt_day.sum().reset_index().sort_values('date')\n",
    "\n",
    "data_preprocessing['add_generalized_names_and_encode_stage'] = lambda dataset: tr.append_columns(\n",
    "    dataset=dataset, \n",
    "    columns=[\n",
    "        'global_item_category_name',\n",
    "        'city_name',\n",
    "        'global_item_category_name_id',\n",
    "        'city_id',\n",
    "    ], \n",
    "    transformers=[\n",
    "        lambda _dataset: _dataset[\"item_category_name\"].apply(\n",
    "            make_cat_name\n",
    "        ),\n",
    "        lambda _dataset: _dataset['shop_name'].apply(\n",
    "            make_city_name\n",
    "        ),\n",
    "        lambda _dataset: LabelEncoder().fit_transform(_dataset['global_item_category_name']),\n",
    "        lambda _dataset: LabelEncoder().fit_transform(_dataset['city_name']),\n",
    "    ]\n",
    ")\n",
    "\n",
    "        \n",
    "data_preprocessing['date_block_num_renaming'] = lambda dataset: dataset.rename(columns={'date_block_num': 'month_block'}, inplace=True)\n",
    "        \n",
    "data_preprocessing['date_encoding_stage'] = lambda dataset: tr.append_columns(\n",
    "    dataset=dataset, \n",
    "    columns=[\n",
    "        'week_block',\n",
    "        'day_block',\n",
    "    ], \n",
    "    transformers=[\n",
    "        lambda _dataset: LabelEncoder().fit_transform(_dataset['date'].dt.to_period('W')),\n",
    "        lambda _dataset: LabelEncoder().fit_transform(_dataset['date'].dt.to_period('D')),\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_preprocessing['create_full_matrix_stage'] = lambda _dataset: _dataset.set_index('date') \\\n",
    "    .groupby([\n",
    "        'shop_id',\n",
    "        'item_category_id',\n",
    "        'month_block',\n",
    "        'city_id',\n",
    "        'global_item_category_name_id',\n",
    "        'id'\n",
    "    ]).item_cnt_day.sum() \\\n",
    "    .reset_index().rename(columns={'item_cnt_day': 'item_cnt_month'}) \\\n",
    "    .groupby(['shop_id', 'item_category_id', 'month_block', 'city_id', 'global_item_category_name_id', 'id']).item_cnt_month.sum().reset_index() \\\n",
    "    .groupby(['month_block', 'id']).item_cnt_month.sum().unstack().fillna(0) \\\n",
    "    .stack().reset_index().rename(columns={0:'item_cnt_month'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "pipeline = Pipeline(\n",
    "    tasks=data_preprocessing, \n",
    "    task_queue = [\n",
    "        'id_merging_stage',\n",
    "        'summarizing_and_name_merging_stage',\n",
    "        'add_generalized_names_and_encode_stage',\n",
    "        'date_block_num_renaming',\n",
    "        'date_encoding_stage',\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "pipeline_test = pipeline(sales)\n",
    "pipeline_train = pipeline(sales_train)\n",
    "\n",
    "if not CONFIG['FETCH_DATA']:\n",
    "    _ = pipeline_test.proceed_all()\n",
    "    _ = pipeline_train.proceed_all()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "task_df = {}\n",
    "if CONFIG['FETCH_DATA'] == False:\n",
    "    task_df['test'] = pipeline_test.result_storage['date_encoding_stage']\n",
    "    task_df['train'] = pipeline_train.result_storage['date_encoding_stage']\n",
    "    load_pickle(task_df['test'], 'task_df_test')\n",
    "    load_pickle(task_df['train'], 'task_df_train')\n",
    "else:\n",
    "    task_df['test'] = from_pickle('task_df_test.pkl')\n",
    "    task_df['train'] = from_pickle('task_df_train.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "idx = task_df['test'].loc[:,['city_id', 'global_item_category_name_id', 'city_name', 'global_item_category_name']].value_counts().sort_index()\n",
    "idx = pd.DataFrame({'id': [i for i in range(idx.size)]}, idx.index)\n",
    "idx.reset_index(inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "task_df['test'] = task_df['test'].merge(idx, on=['city_id', 'global_item_category_name_id', 'city_name', 'global_item_category_name'])\n",
    "task_df['train'] = task_df['train'].merge(idx, on=['city_id', 'global_item_category_name_id', 'city_name', 'global_item_category_name'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "idx['pair_name'] = idx['city_name'] + ' - ' + idx['global_item_category_name']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "task_df_copy = {}\n",
    "\n",
    "task_df_copy['train'] = task_df['train'].copy()\n",
    "\n",
    "task_df_copy['test'] = task_df['test'].copy()\n",
    "task_df['test']['pair_name'] = task_df['test']['city_name'] + ' - ' + task_df['test']['global_item_category_name']\n",
    "\n",
    "task_df['train'] = data_preprocessing['create_full_matrix_stage'](task_df['train'])\n",
    "task_df['test'] = data_preprocessing['create_full_matrix_stage'](task_df['test'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "task_df['train']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_block</th>\n",
       "      <th>id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14887</th>\n",
       "      <td>33</td>\n",
       "      <td>433</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14888</th>\n",
       "      <td>33</td>\n",
       "      <td>434</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14889</th>\n",
       "      <td>33</td>\n",
       "      <td>435</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14890</th>\n",
       "      <td>33</td>\n",
       "      <td>436</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14891</th>\n",
       "      <td>33</td>\n",
       "      <td>437</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14892 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       month_block   id  item_cnt_month\n",
       "0                0    0            66.0\n",
       "1                0    1             0.0\n",
       "2                0    2            20.0\n",
       "3                0    3           240.0\n",
       "4                0    4           263.0\n",
       "...            ...  ...             ...\n",
       "14887           33  433            87.0\n",
       "14888           33  434            98.0\n",
       "14889           33  435            14.0\n",
       "14890           33  436            12.0\n",
       "14891           33  437             9.0\n",
       "\n",
       "[14892 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For future"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def add_aggregation(feature_set, series, name, funcs=[np.mean, np.std]):\n",
    "    for func in funcs:\n",
    "        feature_set[name + f'_{func.__name__}'] = func(series)\n",
    "\n",
    "def target_extractor(month):\n",
    "    return task_df['train'][task_df['train'].month_block == month + 1][['id', 'item_cnt_month']].set_index('id').sort_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "iteration_rule = ExpandedWindowIterator('month_block', target_extractor, min_idx=CONFIG['validation_window']['min_window'], step=1, max_idx=CONFIG['validation_window']['max_window'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "subset_extractor = EntityIterator('id')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "DAYS = [31,28,31,30,31,30,31,31,30,31,30,31]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "city_dynamic = task_df_copy['train'].groupby(['month_block', 'city_id']).item_cnt_day.sum().unstack(-1).fillna(0)\n",
    "category_dynamic = task_df_copy['train'].groupby(['month_block', 'global_item_category_name_id']).item_cnt_day.sum().unstack(-1).fillna(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "thresh = np.percentile(city_dynamic[2], 75)\n",
    "series__ = tr.diff(city_dynamic[2][city_dynamic[2] > thresh].reset_index(), 1).month_block\n",
    "# city_dynamic[2][city_dynamic[2] > thresh].reset_index().month_block.to_list()[-1]\n",
    "series__[series__ > 1].mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8.5"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "def decode_pair(_id):\n",
    "    city = idx.iloc[_id]['city_id']\n",
    "    category = idx.iloc[_id]['global_item_category_name_id']\n",
    "    return city, category\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def generate_feature_row_base(split_x, target, window, _id):\n",
    "    \n",
    "    city_id, category_id = decode_pair(_id)\n",
    "\n",
    "    _city_dynamic = city_dynamic[city_id]\n",
    "    _category_dynamic = category_dynamic[category_id]\n",
    "\n",
    "    _feature_set = {}\n",
    "    _serieses = {}\n",
    "\n",
    "\n",
    "    _feature_set['window'] = window\n",
    "    _feature_set['id'] = _id\n",
    "\n",
    "    _sale_series = split_x.set_index('month_block').item_cnt_month\n",
    "\n",
    "    thresh_75 = np.percentile(_sale_series, 70)\n",
    "    mean_75 = tr.diff(_sale_series[_sale_series >= thresh_75].reset_index(), 1).month_block\n",
    "    mean_75 = mean_75[mean_75 > 1].mean()\n",
    "    last_75 = _sale_series[_sale_series >= thresh_75].reset_index().month_block.to_list()[-1]\n",
    "    \n",
    "    thresh_90 = np.percentile(_sale_series, 90)\n",
    "    mean_90 = tr.diff(_sale_series[_sale_series >= thresh_90].reset_index(), 1).month_block\n",
    "    mean_90 = mean_90[mean_90 > 1].mean()\n",
    "    last_90 = _sale_series[_sale_series >= thresh_90].reset_index().month_block.to_list()[-1]\n",
    "\n",
    "    thresh_20 = np.percentile(_sale_series, 20)\n",
    "    mean_20 = tr.diff(_sale_series[_sale_series <= thresh_20].reset_index(), 1).month_block\n",
    "    mean_20 = mean_20[mean_20 > 1].mean()\n",
    "    last_20 = _sale_series[_sale_series <= thresh_20].reset_index().month_block.to_list()[-1]\n",
    "\n",
    "\n",
    "    _serieses['city_lag_1'] = tr.lag(_city_dynamic, 1, 0)\n",
    "    _serieses['city_diff_1'] = tr.diff(_city_dynamic, 1)\n",
    "\n",
    "    _serieses['category_lag_1'] = tr.lag(_category_dynamic, 1, 0)\n",
    "    _serieses['category_diff_1'] = tr.diff(_category_dynamic, 1)\n",
    "\n",
    "    _serieses['lag_1'] = tr.lag(_sale_series, 1, 0)\n",
    "    _serieses['diff_1'] = tr.diff(_sale_series, 1)\n",
    "    _serieses['diff_2'] = tr.diff(_sale_series, 2)\n",
    "\n",
    "    custom_range = [1, 2, 3, 4, 6, 12]\n",
    "\n",
    "    acf_main = acf(_sale_series, 13)\n",
    "\n",
    "    for i in custom_range:\n",
    "        _feature_set[f'lag_{i}_mul'] = _serieses['lag_1'].to_list()[-i]\n",
    "        _feature_set[f'lag_{i}_mul_acf'] = _serieses['lag_1'].to_list()[-i] * acf_main[i] if _serieses['lag_1'].to_list()[-i] != 0 else 0\n",
    "        _feature_set[f'city_lag_{i}'] = _serieses['city_lag_1'].to_list()[-i]\n",
    "        _feature_set[f'category_lag_{i}'] = _serieses['category_lag_1'].to_list()[-i]\n",
    "\n",
    "    for i in range(1,5):\n",
    "        _feature_set[f'diff_1_{i}'] = _serieses['diff_1'].to_list()[-i]\n",
    "        _feature_set[f'city_diff_1_{i}'] = _serieses['city_diff_1'].to_list()[-i]\n",
    "        _feature_set[f'category_diff_1_{i}'] = _serieses['category_diff_1'].to_list()[-i]\n",
    "\n",
    "    for i in range(1,5):\n",
    "        _feature_set[f'diff_2_{i}'] = _serieses['diff_2'].to_list()[-i]\n",
    "    \n",
    "    add_aggregation(_feature_set, _sale_series, '', [np.min, np.max, np.mean, np.std])\n",
    "    add_aggregation(_feature_set, _sale_series[-12:], 'last_12')\n",
    "    add_aggregation(_feature_set, _sale_series[-6:], 'last_6')\n",
    "    add_aggregation(_feature_set, _sale_series[-2:], 'last_2')\n",
    "    add_aggregation(_feature_set, _serieses['diff_1'], 'diff_1')\n",
    "    add_aggregation(_feature_set, _serieses['diff_2'], 'diff_2')\n",
    "    add_aggregation(_feature_set, _serieses['diff_1'][-12:], 'diff_1_last_12', [np.min, np.max, np.mean, np.std])\n",
    "    add_aggregation(_feature_set, _serieses['diff_1'][-6:], 'diff_1_last_6')\n",
    "    add_aggregation(_feature_set, _serieses['diff_1'][-2:], 'diff_1_last_2')\n",
    "\n",
    "    add_aggregation(_feature_set, _city_dynamic, 'city', [np.min, np.max, np.mean, np.std])\n",
    "    add_aggregation(_feature_set, _category_dynamic, 'category', [np.min, np.max, np.mean, np.std])\n",
    "\n",
    "    add_aggregation(_feature_set, _city_dynamic[-12:], 'city_last_12')\n",
    "    add_aggregation(_feature_set, _city_dynamic[-2:], 'city_last_2')\n",
    "    add_aggregation(_feature_set, _category_dynamic[-12:], 'category_last_12')\n",
    "    add_aggregation(_feature_set, _category_dynamic[-2:], 'category_last_2')\n",
    "\n",
    "    add_aggregation(_feature_set, _serieses['city_diff_1'][-3:], 'city_diff_1_last_3')\n",
    "    add_aggregation(_feature_set, _serieses['category_diff_1'][-3:], 'category_diff_1_last_3')\n",
    "\n",
    "    _feature_set['last_observed'] = _sale_series.values[-1]\n",
    "    _feature_set['time'] = _sale_series.index[-1]\n",
    "    _feature_set['month_number'] = _feature_set['time'] % 12\n",
    "    _feature_set['days_in_month'] = DAYS[_feature_set['month_number']]\n",
    "    _feature_set['target'] = target\n",
    "    _feature_set['category_id'] = category_id\n",
    "    _feature_set['city_id'] = city_id\n",
    "    _feature_set['90_percentile'] = thresh_90 * (1 - last_90 / mean_90)\n",
    "    _feature_set['20_percentile'] = thresh_20 * (1 - last_20 / mean_20)\n",
    "    _feature_set['75_percentile'] = thresh_75 * (1 - last_75 / mean_75)\n",
    "\n",
    "\n",
    "    return pd.DataFrame(_feature_set.items()).set_index(0).transpose()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "train = None\n",
    "\n",
    "if True:\n",
    "    for window, split_x, split_y in iteration_rule(task_df['train']):\n",
    "        as_list = split_y.item_cnt_month.to_list()\n",
    "        for _id, subset in subset_extractor(split_x):\n",
    "            new_feature = generate_feature_row_base(subset, as_list[_id], window, _id)\n",
    "            if train is None:\n",
    "                train = new_feature\n",
    "            else:\n",
    "                train = pd.concat([train, new_feature])\n",
    "            \n",
    "    train = train.reset_index().drop('index', axis=1)\n",
    "    train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    train = train.fillna(0)\n",
    "    load_pickle(train, 'extracted_train')\n",
    "else:\n",
    "    train = from_pickle('extracted_train.pkl')\n",
    "target_test = task_df['test'].rename(columns={'month_block': 'window', 'item_cnt_month': 'target'})"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'acf' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7b1ba1f3e9d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mas_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_cnt_month\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mnew_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_feature_row_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-859e8c6b9529>\u001b[0m in \u001b[0;36mgenerate_feature_row_base\u001b[0;34m(split_x, target, window, _id)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mcustom_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0macf_main\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sale_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcustom_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acf' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "uploader = DatasetUploader('')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "uploader.save(task_df['test'], 'full_dataset.csv')\n",
    "uploader.save(task_df_copy['test'], 'extended_full_dataset.csv')\n",
    "uploader.save(train, 'extracted_features.csv')\n",
    "uploader.save(idx, 'idx.csv')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "ee9e506adb4a3f7fa64fd7b78d744fa60d5969384b878b630c76f52692fa2851"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}